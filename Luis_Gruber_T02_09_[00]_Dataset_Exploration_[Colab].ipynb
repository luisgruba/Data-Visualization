{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Luis Gruber - T02-09 [00] Dataset Exploration [Colab]",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "jx_FnF6HFucc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisgruba/Data-Visualization/blob/master/Luis_Gruber_T02_09_%5B00%5D_Dataset_Exploration_%5BColab%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jx_FnF6HFucc"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSdG7cSNFro-",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_FdRu8E0F6EJ"
      },
      "source": [
        "# Dataset Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_G6coOSrSud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import altair as alt\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import seaborn as sns\n",
        "import calendar\n",
        "from vega_datasets import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mm5d3zEpKE00"
      },
      "source": [
        "In this project you will be divided into small groups (two or three people). You will be pointed to a dataset and asked to create a model to solve a problem. Over the course of the day, your team will explore the data and train the best model you can for solving the problem. At the end of the day, your team will give a short presentation about your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2iIQ-XduKJZz"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B-TOrwufKQhD"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Acquire and load dataset(s) into the Pandas structures.\n",
        "* Inspect data columns description and statistics.\n",
        "* Explore data to understand relationship between features.\n",
        "* Draw data insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LqnO7DiKmwi"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Introduction to Colab\n",
        "* Intermediate Python\n",
        "* Intermediate Pandas\n",
        "* Visualizations\n",
        "* Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3qhlIRMGLDea"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "240 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nb9YD_6cWefp"
      },
      "source": [
        "### Deliverables\n",
        "\n",
        "1. A copy of this Colab notebook containing your code and responses to the ethical considerations below.\n",
        "1. A group presentation. After everyone is done, we will ask each group to stand in front of the class and give a brief presentation about what they have done in this lab. The presentation can be a code walkthrough, a group discussion, a slide show, or any other means that conveys what you did over the course of the day and what you learned. If you do create any artifacts for your presentation, please share them in the class folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dZj2NF0gLGjp"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "This project is graded in separate sections that each contribute a percentage of the total score:\n",
        "\n",
        "1. Explore data to gain insights (80%)\n",
        "1. Ethical Implications (10%)\n",
        "1. Project Presentation (10%)\n",
        "\n",
        "#### Building and Using a Model\n",
        "\n",
        "There are 6 demonstrations of competency listed in the problem statement below. Each competency is graded on a 3 point scale for a total of 18 available points. The following rubric will be used:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at the competency |\n",
        "| 1      | Attempted competency, but in an incorrect manner |\n",
        "| 2      | Attempted competency correctly, but sub-optimally |\n",
        "| 3      | Successful demonstration of competency |\n",
        "\n",
        "The demonstrations of competency show that the team knows how to use the tools of a data scientist, but they are not a good judge of \"thinking like a data scientist\". 3 additional points will be graded on the teams demonstration of skillful application of data science concepts and graded on the following rubric:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Created a generic model with little insight |\n",
        "| 2      | Performed some basic data science processes and patterns |\n",
        "| 3      | Demonstrated mastery of data science and exploration concepts learned so far |\n",
        "\n",
        "#### Ethical Implications\n",
        "\n",
        "There are six questions in the **Ethical Implications** secion. Each question is worth 2 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at question or answer was off-topic or didn't make sense |\n",
        "| 1      | Question was answered, but answer missed important considerations  |\n",
        "| 2      | Answer adequately considered ethical implications |\n",
        "\n",
        "#### Project Presentation\n",
        "\n",
        "The project presentation will be graded on participation. All members of a team should actively participate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JzEoFw-TPi7r"
      },
      "source": [
        "## Team\n",
        "\n",
        "Please enter your team members names in the placeholders in this text area:\n",
        "\n",
        "*   *Team Member Placeholder*\n",
        "*   *Team Member Placeholder*\n",
        "*   *Team Member Placeholder*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a0-9HPLU43Xf"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8rqFJ-Ch4_mU"
      },
      "source": [
        "## Exercise 1: Coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cr12EFb2WQym"
      },
      "source": [
        "[Kaggle](http://www.kaggle.com) hosts a [dataset containing US airline on-time statistics and delay data](https://www.kaggle.com/giovamata/airlinedelaycauses) from the [US Department of Transportation's Bureau of Transportation Statistics (BTS)](https://www.bts.gov/). In this project we will **use flight statistics data to gain insights into US airports and airlines flights in 2008**.\n",
        "\n",
        "You are free to use any toolkit that we have covered in this class to solve the problem. That should be at least Pandas and Matplotlib or Seaborn.\n",
        "\n",
        "Important details:\n",
        "\n",
        "* The [dataset](https://www.kaggle.com/giovamata/airlinedelaycauses) consists of one file, DelayedFlights.csv.\n",
        "* The column we are trying to predict is 'time_in_shelter_days'.\n",
        "* Do not use any outcome data as features for training the model. We want to be able to predict the time in shelter for any given animal at intake.\n",
        "* Not all animals have outcomes. Not all outcomes are adoption.\n",
        "\n",
        "**Graded** demonstrations of competency:\n",
        "1. Get the data into a Python object.\n",
        "1. Inspect the data for columns' datatype and statistics.\n",
        "1. Explore the data programmatically and visually.\n",
        "1. Produce answer and visualization where applicable for at least 3 questions.  Pick from the list of questions below or come up with one yourself, and talk about any insight if any:\n",
        "\n",
        "  * Which US airports is the busiest airports?  Decide how you'd like to measure it, eg: by annual, monthly, or daily flight traffic?\n",
        "  * Of the 2008 flights that are __actually delayed__, think about:\n",
        "    * Which 10 US airlines have the most delays measured it by flight count?\n",
        "    * Which 10 US airlines have the most delays measured it by average length of delay?\n",
        "    * Similarly, you can get the top 10 US aiports instead of airlines for the previous questions.  Which 10 US airports have the most delays measured it by flight count?\n",
        "    * Which 10 US airports have the most delays measured it by flight count?\n",
        "  * More analysis:\n",
        "    * Is there patterns on how flight delays are distributed across different hours of the day?\n",
        "    * Similarly, how about across months or season?  Maybe correllate to seasonal weather impact, holiday traffic, etc.\n",
        "    * If you look at the data beyond the top 10 US airlines or airports is the data show linearity as you examine top 40 US airlines or airports.\n",
        "    * Reexamine the figures you worked on above by reason for delay.\n",
        "    * Drill down on particular airport, airline or even origin and arrival airport pairs - and examine flight frequencies, delays, time of day or year, etc.\n",
        "  * or any questions that your team come up with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgFU38b7rfbv"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wOdOl0qqPyL-",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Read the dataset into a pandas dataframe\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hghjsHC9jJZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_filename = \"./DelayedFlights.csv\"\n",
        "flight_df = pd.read_csv(dataset_filename, encoding='latin-1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUUR6rPCl99M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = flight_df\n",
        "print(df.shape)\n",
        "df = df.dropna()\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fc0hGN0EguA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origin_delay = df[['DepDelay', 'Origin', 'Month', 'DayofMonth']]\n",
        "origin_delay.head(1500)\n",
        "\n",
        "airports = list(set(df['Origin']))\n",
        "months = list(set(df['Month']))\n",
        "airports.sort()\n",
        "\n",
        "origin_delay = origin_delay.set_index(['Month', 'DepDelay'])\n",
        "origin_delay = origin_delay.sort_index(ascending = False)\n",
        "#origin_delay = origin_delay.groupby(['Month', 'Origin'])[['DepDelay']].mean()\n",
        "origin_delay = origin_delay.reset_index()\n",
        "origin_delay = origin_delay.set_index('Month')\n",
        "origin_delay\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFdq2vVqpCxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dest_delay = df[['ArrDelay', 'Dest', 'Month', 'DayofMonth']]\n",
        "dest_delay.head(1500)\n",
        "\n",
        "airports = list(set(df['Dest']))\n",
        "months = list(set(df['Month']))\n",
        "airports.sort()\n",
        "\n",
        "dest_delay = dest_delay.set_index(['Month', 'ArrDelay'])\n",
        "dest_delay = dest_delay.sort_index(ascending = False)\n",
        "#origin_delay = origin_delay.groupby(['Month', 'Origin'])[['DepDelay']].mean()\n",
        "dest_delay = dest_delay.reset_index()\n",
        "dest_delay = dest_delay.set_index('Month')\n",
        "dest_delay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXJDKNmbTFI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_delay_df = pd.DataFrame()\n",
        "for month in range(12,0,-1):\n",
        "  reduced_delay_df = pd.concat([reduced_delay_df, origin_delay.loc[month][:50]])\n",
        "\n",
        "reduced_delay_df = reduced_delay_df.reset_index()\n",
        "#d = dict(enumerate(calendar.month_abbr))\n",
        "#reduced_delay_df['Month'] = reduced_delay_df['Month'].map(d)\n",
        "\n",
        "reduced_delay_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfjDCq2Uplt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_delay_df = pd.DataFrame()\n",
        "for month in range(12,0,-1):\n",
        "  reduced_delay_df = pd.concat([reduced_delay_df, origin_delay.loc[month][:50]])\n",
        "\n",
        "reduced_delay_df = reduced_delay_df.reset_index()\n",
        "\n",
        "reduced_delay_df['Origin'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0mWJfN7rq_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_arr_delay = pd.DataFrame()\n",
        "for month in range(12,0,-1):\n",
        "  reduced_arr_delay = pd.concat([reduced_arr_delay, dest_delay.loc[month][:100]])\n",
        "\n",
        "reduced_arr_delay = reduced_arr_delay.reset_index()\n",
        "\n",
        "reduced_arr_delay['Dest'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfUHox-JutvN",
        "colab_type": "text"
      },
      "source": [
        "We are dealing with 302 airports and will evaluate delays for ranking the top 50 worst by month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxnImwQF5pUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alt.Chart(reduced_delay_df.reset_index()).mark_point().encode(\n",
        "     alt.X('Month:Q'),\n",
        "     y='DepDelay:Q',\n",
        "     color='Origin:N',\n",
        "     tooltip = ['Origin', 'DepDelay']\n",
        " ).interactive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr1z2YTMZfDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "airports = data.airports()\n",
        "airports = airports[['iata', 'latitude', 'longitude']]\n",
        "combi = reduced_delay_df.merge(airports, how = 'left', left_on = 'Origin', right_on = 'iata')\n",
        "combi = combi.drop(columns=['iata', 'DayofMonth'])\n",
        "\n",
        "airports_arr = data.airports()\n",
        "airports_arr = airports_arr[['iata', 'latitude', 'longitude']]\n",
        "arr_combi = reduced_arr_delay.merge(airports_arr, how = 'left', left_on = 'Dest', right_on = 'iata')\n",
        "arr_combi = arr_combi.drop(columns=['iata', 'DayofMonth'])\n",
        "#combi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL0_MsHm2seq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# US states background\n",
        "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
        "\n",
        "background = alt.Chart(states).mark_geoshape(\n",
        "    fill='darkorange',\n",
        "    stroke='white'\n",
        ").properties(\n",
        "    width=550,\n",
        "    height=600\n",
        ").project('albersUsa')\n",
        "\n",
        "#slider = alt.binding_range(list)\n",
        "months =[\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
        "\n",
        "# input_slider = alt.binding_select(options = months)\n",
        "\n",
        "slider = alt.binding_range(min=1, max=12, step=1)\n",
        "selection = alt.selection_single(fields=['Month'], bind=slider, name = \"Current\", init={'Month': 1})\n",
        "\n",
        "color_1 = alt.condition(selection, alt.Color('DepDelay', aggregate='mean', type='quantitative'),alt.value('black'))\n",
        "color_2 = alt.condition(selection, alt.Color('ArrDelay', aggregate='mean', type='quantitative'),alt.value('black'))\n",
        "\n",
        "\n",
        "points_delay = alt.Chart(combi).mark_circle(\n",
        "    size=70,\n",
        ").encode(\n",
        "    longitude='longitude:Q',\n",
        "    latitude='latitude:Q',\n",
        "    tooltip=['Origin', 'DepDelay', 'Month'],\n",
        "    color = color_1\n",
        ").add_selection(\n",
        "    selection\n",
        ").transform_filter(\n",
        "    selection\n",
        ")\n",
        "\n",
        "points_arrive = alt.Chart(arr_combi).mark_circle(\n",
        "    size=80,\n",
        ").encode(\n",
        "    longitude='longitude:Q',\n",
        "    latitude='latitude:Q',\n",
        "    tooltip=['Dest', 'ArrDelay', 'Month'],\n",
        "    color = color_2\n",
        ").add_selection(\n",
        "    selection\n",
        ").transform_filter(\n",
        "    selection\n",
        ")\n",
        "\n",
        "\n",
        "(background + points_delay) | (background + points_arrive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2IY331QgBEm5"
      },
      "source": [
        "## Exercise 2: Ethical Implications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uK8XzfVHLi1K"
      },
      "source": [
        "Even the most basic of models have the potential to affect segments of the population in different ways. It is important to consider how your model might positively and negative effect different types of users.\n",
        "\n",
        "In this section of the project you will reflect on the positive and negative implications of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BqyxriWE53Du"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_U3L0F9FLmwa"
      },
      "source": [
        "**Positive Impact**\n",
        "\n",
        "Your model is trying to solve a problem. Think about who will benefit from that problem being solved and write a brief narrative about how the model will help.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g582VerYL0so"
      },
      "source": [
        "This model would allow users to see specific airport's delayed timings. This can help people plan their trips better and potentially schedule around specific times- especially people who travel a lot. This can also help airlines plan their trips better to schedule trips to specific places at certain times (i.e., to prevent long delays due to weather."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALr018eQMuUw"
      },
      "source": [
        "**Negative Impact**\n",
        "\n",
        "Models don't often have universal benefit. Think about who might be negatively impacted by the predictions your model is making. This person or persons might not be directly using the model, but instead might be impacted indirectly.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "We8_W4WtNDLw"
      },
      "source": [
        "Showing how many delays occur at certain airports, could cause an airline or airport to experience a lower number of passengers. This lower number of people departing from the airport would also impact neighboring airports by causing them to see a larger population of travelers in which they also must adjust accordingly. It would impact neighboring airlines who would have to adjust for more passengers as well. A secondary impact this dataset would have would be on the employees of the airports as more delays can cause fewer flights out of the airport which can result in having fewer workers. Some of the outputs this model produces are affected by multivariate system, with factors such as weather and season affecting airports beyond their control."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07J-8ljpL85I"
      },
      "source": [
        "**Bias**\n",
        "\n",
        "Models can be bias for many reasons. The bias can come from the data used to build the model (eg. sampling, data collection methods, available sources) and from the interpretation of the predictions generated by the model.\n",
        "\n",
        "Think of at least two ways that bias might have been introduced to your model and explain both below.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jg_PSw3NMyFX"
      },
      "source": [
        "One source of bias in the model could be some selection bias. The number of flights coming out of a smaller airport should be viewed differently compared to a very large international airport that sees hundreds of flights daily, however, this dataset views them equally. This skews our data by weighing the flights the same, despite there being a different value. Smaller airports also have a greater chance of being in a location with more weather that would delay a flight. A second issue with having this bias is that the data does not contain more information about longer flights (flights anywhere that are not to the contiguous United States, such as international flights or flights to AK and HI). (International) flights typically use larger aircrafts which can cause a different sort of delay in taxing due to having a larger passenger count, longer refueling and thus a larger preparation time and turnover rate.\n",
        "\n",
        "This dataset also doesn't include if any of these flights are connecting flights. If we were able to follow trend lines of specific airlines, we may be able to understand if there is more correlation between where those flights are taking off from and how that influences the rest of their trips that day.\n",
        "\n",
        "A flight delay is when an airline flight takes off and/or lands later than its scheduled time. The Federal Aviation Administration (FAA) considers a flight to be delayed when it is 15 minutes later than its scheduled time. However, our data shows that our smallest delay time is 6 minutes. With this information, we can confirm that there may be some automation bias involved. (Automation bias is a tendency to favor results generated by automated systems over those generated by non-automated systems, irrespective of the error rates of each.) If employees are favoring results generated by automated systems, then it is possible that those systems and models in place could be inaccurate because they are not checking the accuracy of the model. This could lead to some bias towards specific airlines if they are leaving less than 15 minutes later than expected but having that small delay count as a flight delay by the U.S. Department of Transportation's (DOT)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7j9AWdJLMTJI"
      },
      "source": [
        "**Changing the Dataset to Mitigate Bias**\n",
        "\n",
        "Bias datasets are one of the primary ways in which bias is introduced to a machine learning model. Look back at the input data that you fed to your model. Think about how you might change something about the data to reduce bias in your model.\n",
        "\n",
        "What change or changes could you make to your dataset less bias? Consider the data that you have, how and where that data was collected, and what other sources of data might be used to reduce bias.\n",
        "\n",
        "Write a summary of change that could be made to your input data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yzzfrQ-xNZo5"
      },
      "source": [
        "One change that could be made to the dataset to mitigate the bias is to specify how the data was obtained. The Bureau of Transportation Statistics (BTS) wrote that the major data gaps identified in the Statement included statistics on domestic and international flows of freight and passenger traffic by all modes, the extent, and performance of intermodal connections, the financial and operating characteristics of smaller carriers, and the costs of both for-hire and private transportation incurred by each sector of the economy. Filling these gaps would make our dataset less biased as we would have a more specified look into why a flight could be delayed and whether or not the cause is due to humans, weather, or something different. This data is also coming from 2008, yet there is another source from the BTS taken from a more recent year, 2015. These new reports are released every month, meaning the most updated version should be available often. The final change we could make to mitigate bias is to gain a better understanding of the airlines since there are many parent companies with smaller companies underneath them. This would help our analysis by helping us understand if there is a difference in delays between airlines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ePs6hpLiMNSx"
      },
      "source": [
        "**Changing the Model to Mitigate Bias**\n",
        "\n",
        "Is there any way to reduce bias by changing the model itself? This could include modifying algorithmic choices, tweaking hyperparameters, etc.\n",
        "\n",
        "Write a brief summary of changes that you could make to help reduce bias in your model.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bZ3PS8bRNRCv"
      },
      "source": [
        "Our model only looked at the flight delays timings specified by the airline, airplane number, and the time of arrival and departure among other details. There is a slight bias in the airline specifications since there is very little information on the overall popularity and traffic that occurs. One way to reduce bias is by modifying the columns and including the average traffic passing through each airport. A second way to mitigate the bias in our model is to join in a dataset about weather patterns. Places this dataset could be obtained is through NOAA, any weather-related news source, or a GitHub/Kaggle. Adding on this data would help our model understand specific causes of delays and when they occur, which could be used to show what time and where to fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYY7lk55MgdX"
      },
      "source": [
        "**Mitigating Bias Downstream**\n",
        "\n",
        "Models make predictions. Downstream processes make decisions. What processes and/or rules should be in place for people and systems interpreting and acting on the results of your model to reduce the bias? Describe these below.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mp3TkmalNcR-"
      },
      "source": [
        "A process (and rule) that should be put in place for people interpreting these predictions should include not ignoring the outliers. There were numerous flights that skewed our flights due to having an extensive delay time (the longest being almost 48 hours). By having humans process these outliers and understand the causes, they would be able to help lower the number of extensive delays. A secondary rule that should be also be put in place for people or systems is to review the data annually. By reviewing past data, one can determine quite a few patterns including popular days to travel and popular days for delays. This would help cross-check a modelâ€™s predictions by using human logic to ensure the model is working efficiently.\n",
        "\n"
      ]
    }
  ]
}